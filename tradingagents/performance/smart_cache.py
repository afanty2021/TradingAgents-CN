"""
æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
æä¾›å¤šçº§ç¼“å­˜ã€æ™ºèƒ½å†³ç­–å’Œè‡ªåŠ¨ä¼˜åŒ–åŠŸèƒ½
"""

import time
import hashlib
import json
import logging
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import threading
from collections import OrderedDict
import math

from tradingagents.exceptions import CacheError
from tradingagents.utils.logging_init import get_logger

logger = get_logger(__name__)


class CacheLevel(Enum):
    """ç¼“å­˜çº§åˆ«"""
    MEMORY = "memory"      # å†…å­˜ç¼“å­˜ (æœ€å¿«)
    REDIS = "redis"        # Redisç¼“å­˜ (è¾ƒå¿«)
    MONGODB = "mongodb"    # MongoDBç¼“å­˜ (æŒä¹…åŒ–)
    FILE = "file"          # æ–‡ä»¶ç¼“å­˜ (æœ€æ…¢)


class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥"""
    LRU = "lru"              # æœ€è¿‘æœ€å°‘ä½¿ç”¨
    LFU = "lfu"              # æœ€å°‘ä½¿ç”¨é¢‘ç‡
    TTL = "ttl"              # æ—¶é—´è¿‡æœŸ
    ADAPTIVE = "adaptive"      # è‡ªé€‚åº”ç­–ç•¥


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    created_at: float = field(default_factory=time.time)
    last_accessed: float = field(default_factory=time.time)
    access_count: int = 0
    ttl: Optional[float] = None
    size_bytes: int = 0
    cost: float = 0.0  # è·å–æˆæœ¬ï¼ˆæ—¶é—´ï¼‰
    hit_count: int = 0  # å‘½ä¸­æ¬¡æ•°
    miss_count: int = 0  # æœªå‘½ä¸­æ¬¡æ•°

    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if self.ttl is None:
            return False
        return time.time() > (self.created_at + self.ttl)

    def update_access(self):
        """æ›´æ–°è®¿é—®ä¿¡æ¯"""
        self.last_accessed = time.time()
        self.access_count += 1

    def calculate_score(self, current_time: float) -> float:
        """è®¡ç®—ç¼“å­˜åˆ†æ•°ï¼ˆç”¨äºLRU/LFUç­–ç•¥ï¼‰"""
        age = current_time - self.last_accessed
        frequency = self.access_count

        # ç»¼åˆåˆ†æ•°ï¼ˆæ–°è®¿é—® + é«˜é¢‘ç‡ = é«˜åˆ†æ•°ï¼‰
        return frequency * 1000 - age


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    total_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    evictions: int = 0
    memory_usage_bytes: int = 0
    avg_access_time_ms: float = 0.0
    hit_rate: float = 0.0

    def update_hit(self):
        """æ›´æ–°å‘½ä¸­ç»Ÿè®¡"""
        self.total_requests += 1
        self.cache_hits += 1
        self.hit_rate = (self.cache_hits / self.total_requests) * 100

    def update_miss(self):
        """æ›´æ–°æœªå‘½ä¸­ç»Ÿè®¡"""
        self.total_requests += 1
        self.cache_misses += 1
        self.hit_rate = (self.cache_hits / self.total_requests) * 100

    def update_eviction(self):
        """æ›´æ–°é©±é€ç»Ÿè®¡"""
        self.evictions += 1


class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self,
                 max_memory_size: int = 100 * 1024 * 1024,  # 100MB
                 max_entries: int = 10000,
                 strategy: CacheStrategy = CacheStrategy.ADAPTIVE,
                 enable_redis: bool = True,
                 enable_mongodb: bool = True):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨

        Args:
            max_memory_size: æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
            max_entries: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
            strategy: ç¼“å­˜ç­–ç•¥
            enable_redis: æ˜¯å¦å¯ç”¨Redis
            enable_mongodb: æ˜¯å¦å¯ç”¨MongoDB
        """
        self.max_memory_size = max_memory_size
        self.max_entries = max_entries
        self.strategy = strategy

        # å¤šçº§ç¼“å­˜
        self.memory_cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self.redis_cache = None
        self.mongodb_cache = None
        self.file_cache_path = "/tmp/tradingagents_cache.json"

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = CacheStats()
        self.lock = threading.RLock()

        # åˆå§‹åŒ–å¤–éƒ¨ç¼“å­˜
        if enable_redis:
            self._init_redis_cache()
        if enable_mongodb:
            self._init_mongodb_cache()

        logger.info(f"ğŸš€ æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ - ç­–ç•¥: {strategy.value}")

    def _init_redis_cache(self):
        """åˆå§‹åŒ–Redisç¼“å­˜"""
        try:
            import redis
            self.redis_cache = redis.Redis(
                host='localhost',
                port=6379,
                db=0,
                decode_responses=True,
                socket_timeout=5,
                socket_connect_timeout=5
            )
            # æµ‹è¯•è¿æ¥
            self.redis_cache.ping()
            logger.info("âœ… Redisç¼“å­˜è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Redisç¼“å­˜è¿æ¥å¤±è´¥: {e}")
            self.redis_cache = None

    def _init_mongodb_cache(self):
        """åˆå§‹åŒ–MongoDBç¼“å­˜"""
        try:
            from pymongo import MongoClient
            self.mongodb_cache = MongoClient(
                'mongodb://localhost:27017/',
                serverSelectionTimeoutMS=5000
            )
            # æµ‹è¯•è¿æ¥
            self.mongodb_cache.admin.command('ping')
            self.mongodb_db = self.mongodb_cache.tradingagents_cache
            self.mongodb_collection = self.mongodb_db.cache_entries
            logger.info("âœ… MongoDBç¼“å­˜è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ MongoDBç¼“å­˜è¿æ¥å¤±è´¥: {e}")
            self.mongodb_cache = None

    def get(self, key: str, default: Any = None,
            level: CacheLevel = CacheLevel.MEMORY) -> Any:
        """
        è·å–ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            default: é»˜è®¤å€¼
            level: ä¼˜å…ˆä½¿ç”¨çš„ç¼“å­˜çº§åˆ«

        Returns:
            ç¼“å­˜å€¼æˆ–é»˜è®¤å€¼
        """
        start_time = time.time()

        with self.lock:
            try:
                # 1. å°è¯•å†…å­˜ç¼“å­˜
                if level == CacheLevel.MEMORY:
                    value = self._get_from_memory(key)
                    if value is not None:
                        self.stats.update_hit()
                        self._record_access_time(start_time)
                        return value

                # 2. å°è¯•Redisç¼“å­˜
                if level in [CacheLevel.REDIS, CacheLevel.MEMORY] and self.redis_cache:
                    value = self._get_from_redis(key)
                    if value is not None:
                        self.stats.update_hit()
                        # æå‡åˆ°å†…å­˜ç¼“å­˜
                        if level == CacheLevel.REDIS:
                            self._set_to_memory(key, value, ttl=3600)
                        self._record_access_time(start_time)
                        return value

                # 3. å°è¯•MongoDBç¼“å­˜
                if level in [CacheLevel.MONGODB, CacheLevel.REDIS, CacheLevel.MEMORY] and self.mongodb_cache:
                    value = self._get_from_mongodb(key)
                    if value is not None:
                        self.stats.update_hit()
                        # æå‡åˆ°ä¸Šçº§ç¼“å­˜
                        if level == CacheLevel.MONGODB:
                            self._set_to_memory(key, value, ttl=7200)
                            if self.redis_cache:
                                self._set_to_redis(key, value, ttl=7200)
                        self._record_access_time(start_time)
                        return value

                # 4. å°è¯•æ–‡ä»¶ç¼“å­˜
                value = self._get_from_file(key)
                if value is not None:
                    self.stats.update_hit()
                    # æå‡åˆ°ä¸Šçº§ç¼“å­˜
                    self._set_to_memory(key, value, ttl=14400)
                    if self.redis_cache:
                        self._set_to_redis(key, value, ttl=14400)
                    self._record_access_time(start_time)
                    return value

                # 5. ç¼“å­˜æœªå‘½ä¸­
                self.stats.update_miss()
                self._record_access_time(start_time)
                return default

            except Exception as e:
                logger.error(f"è·å–ç¼“å­˜å¤±è´¥ {key}: {e}")
                self.stats.update_miss()
                return default

    def set(self, key: str, value: Any, ttl: Optional[float] = None,
              levels: List[CacheLevel] = None) -> bool:
        """
        è®¾ç½®ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
            levels: è¦è®¾ç½®çš„ç¼“å­˜çº§åˆ«åˆ—è¡¨

        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if levels is None:
            levels = [CacheLevel.MEMORY, CacheLevel.REDIS, CacheLevel.MONGODB]

        try:
            with self.lock:
                success = True

                # è®¡ç®—å€¼å¤§å°
                value_size = self._calculate_size(value)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦é©±é€
                if self._should_evict(key, value_size):
                    self._evict_entries(value_size)

                # è®¾ç½®åˆ°æŒ‡å®šçº§åˆ«
                for level in levels:
                    if level == CacheLevel.MEMORY:
                        success &= self._set_to_memory(key, value, ttl)
                    elif level == CacheLevel.REDIS and self.redis_cache:
                        success &= self._set_to_redis(key, value, ttl)
                    elif level == CacheLevel.MONGODB and self.mongodb_cache:
                        success &= self._set_to_mongodb(key, value, ttl)

                return success

        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜å¤±è´¥ {key}: {e}")
            return False

    def delete(self, key: str, levels: List[CacheLevel] = None) -> bool:
        """
        åˆ é™¤ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            levels: è¦åˆ é™¤çš„ç¼“å­˜çº§åˆ«åˆ—è¡¨

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if levels is None:
            levels = [CacheLevel.MEMORY, CacheLevel.REDIS, CacheLevel.MONGODB]

        try:
            with self.lock:
                success = True

                for level in levels:
                    if level == CacheLevel.MEMORY and key in self.memory_cache:
                        del self.memory_cache[key]
                    elif level == CacheLevel.REDIS and self.redis_cache:
                        self.redis_cache.delete(key)
                    elif level == CacheLevel.MONGODB and self.mongodb_cache:
                        self.mongodb_collection.delete_one({'key': key})

                return success

        except Exception as e:
            logger.error(f"åˆ é™¤ç¼“å­˜å¤±è´¥ {key}: {e}")
            return False

    def clear(self, level: Optional[CacheLevel] = None):
        """
        æ¸…ç©ºç¼“å­˜

        Args:
            level: è¦æ¸…ç©ºçš„ç¼“å­˜çº§åˆ«ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨æ¸…ç©º
        """
        try:
            with self.lock:
                if level is None or level == CacheLevel.MEMORY:
                    self.memory_cache.clear()
                    self.stats.memory_usage_bytes = 0

                if level is None or level == CacheLevel.REDIS and self.redis_cache:
                    self.redis_cache.flushdb()

                if level is None or level == CacheLevel.MONGODB and self.mongodb_cache:
                    self.mongodb_collection.delete_many({})

                logger.info(f"âœ… ç¼“å­˜å·²æ¸…ç©º: {level.value if level else 'å…¨éƒ¨'}")

        except Exception as e:
            logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")

    def _get_from_memory(self, key: str) -> Optional[Any]:
        """ä»å†…å­˜ç¼“å­˜è·å–"""
        entry = self.memory_cache.get(key)
        if entry is None:
            return None

        if entry.is_expired():
            del self.memory_cache[key]
            return None

        entry.update_access()
        return entry.value

    def _get_from_redis(self, key: str) -> Optional[Any]:
        """ä»Redisç¼“å­˜è·å–"""
        try:
            data = self.redis_cache.get(key)
            if data is None:
                return None

            cache_data = json.loads(data)
            if cache_data.get('ttl') and time.time() > cache_data['created_at'] + cache_data['ttl']:
                self.redis_cache.delete(key)
                return None

            return cache_data.get('value')
        except Exception as e:
            logger.debug(f"Redisè·å–å¤±è´¥ {key}: {e}")
            return None

    def _get_from_mongodb(self, key: str) -> Optional[Any]:
        """ä»MongoDBç¼“å­˜è·å–"""
        try:
            doc = self.mongodb_collection.find_one({'key': key})
            if doc is None:
                return None

            if doc.get('ttl') and time.time() > doc['created_at'] + doc['ttl']:
                self.mongodb_collection.delete_one({'key': key})
                return None

            return doc.get('value')
        except Exception as e:
            logger.debug(f"MongoDBè·å–å¤±è´¥ {key}: {e}")
            return None

    def _get_from_file(self, key: str) -> Optional[Any]:
        """ä»æ–‡ä»¶ç¼“å­˜è·å–"""
        try:
            import os
            if not os.path.exists(self.file_cache_path):
                return None

            with open(self.file_cache_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)

            if key not in cache_data:
                return None

            entry_data = cache_data[key]
            if entry_data.get('ttl') and time.time() > entry_data['created_at'] + entry_data['ttl']:
                del cache_data[key]
                self._save_file_cache(cache_data)
                return None

            return entry_data.get('value')
        except Exception as e:
            logger.debug(f"æ–‡ä»¶ç¼“å­˜è·å–å¤±è´¥ {key}: {e}")
            return None

    def _set_to_memory(self, key: str, value: Any, ttl: Optional[float] = None) -> bool:
        """è®¾ç½®åˆ°å†…å­˜ç¼“å­˜"""
        try:
            entry = CacheEntry(
                key=key,
                value=value,
                ttl=ttl,
                size_bytes=self._calculate_size(value)
            )

            self.memory_cache[key] = entry
            self._update_memory_usage()

            # é©±é€ç­–ç•¥
            if len(self.memory_cache) > self.max_entries:
                self._evict_by_strategy()

            return True
        except Exception as e:
            logger.error(f"å†…å­˜ç¼“å­˜è®¾ç½®å¤±è´¥ {key}: {e}")
            return False

    def _set_to_redis(self, key: str, value: Any, ttl: Optional[float] = None) -> bool:
        """è®¾ç½®åˆ°Redisç¼“å­˜"""
        try:
            cache_data = {
                'value': value,
                'created_at': time.time(),
                'ttl': ttl
            }

            serialized = json.dumps(cache_data, default=str)
            if ttl:
                self.redis_cache.setex(key, int(ttl), serialized)
            else:
                self.redis_cache.set(key, serialized)

            return True
        except Exception as e:
            logger.error(f"Redisç¼“å­˜è®¾ç½®å¤±è´¥ {key}: {e}")
            return False

    def _set_to_mongodb(self, key: str, value: Any, ttl: Optional[float] = None) -> bool:
        """è®¾ç½®åˆ°MongoDBç¼“å­˜"""
        try:
            cache_data = {
                'key': key,
                'value': value,
                'created_at': time.time(),
                'ttl': ttl
            }

            # å¦‚æœæœ‰TTLï¼Œè®¾ç½®è¿‡æœŸç´¢å¼•
            if ttl:
                cache_data['expire_at'] = time.time() + ttl

            self.mongodb_collection.replace_one(
                {'key': key},
                cache_data,
                upsert=True
            )

            return True
        except Exception as e:
            logger.error(f"MongoDBç¼“å­˜è®¾ç½®å¤±è´¥ {key}: {e}")
            return False

    def _should_evict(self, new_key: str, new_size: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é©±é€"""
        # æ£€æŸ¥æ¡ç›®æ•°é‡é™åˆ¶
        if len(self.memory_cache) >= self.max_entries:
            return True

        # æ£€æŸ¥å†…å­˜å¤§å°é™åˆ¶
        if self.stats.memory_usage_bytes + new_size > self.max_memory_size:
            return True

        return False

    def _evict_entries(self, required_space: int):
        """é©±é€ç¼“å­˜æ¡ç›®"""
        entries_to_evict = []

        # è®¡ç®—éœ€è¦é‡Šæ”¾çš„ç©ºé—´
        current_time = time.time()
        total_freed = 0

        # æ ¹æ®ç­–ç•¥é€‰æ‹©é©±é€æ¡ç›®
        if self.strategy == CacheStrategy.LRU:
            entries = sorted(
                self.memory_cache.items(),
                key=lambda x: x[1].last_accessed
            )
        elif self.strategy == CacheStrategy.LFU:
            entries = sorted(
                self.memory_cache.items(),
                key=lambda x: x[1].access_count
            )
        else:  # ADAPTIVE
            entries = sorted(
                self.memory_cache.items(),
                key=lambda x: x[1].calculate_score(current_time)
            )

        # é€‰æ‹©è¦é©±é€çš„æ¡ç›®
        for key, entry in entries:
            entries_to_evict.append(key)
            total_freed += entry.size_bytes

            if total_freed >= required_space:
                break

        # æ‰§è¡Œé©±é€
        for key in entries_to_evict:
            if key in self.memory_cache:
                entry = self.memory_cache[key]
                del self.memory_cache[key]
                self.stats.update_eviction()

        self._update_memory_usage()

    def _evict_by_strategy(self):
        """æ ¹æ®ç­–ç•¥é©±é€å•ä¸ªæ¡ç›®"""
        if not self.memory_cache:
            return

        if self.strategy == CacheStrategy.LRU:
            # ç§»é™¤æœ€ä¹…æœªè®¿é—®çš„
            oldest_key = min(
                self.memory_cache.keys(),
                key=lambda k: self.memory_cache[k].last_accessed
            )
        elif self.strategy == CacheStrategy.LFU:
            # ç§»é™¤æœ€å°‘ä½¿ç”¨çš„
            least_used_key = min(
                self.memory_cache.keys(),
                key=lambda k: self.memory_cache[k].access_count
            )
        else:  # ADAPTIVE
            current_time = time.time()
            worst_key = min(
                self.memory_cache.keys(),
                key=lambda k: self.memory_cache[k].calculate_score(current_time)
            )
            oldest_key = worst_key

        if oldest_key in self.memory_cache:
            del self.memory_cache[oldest_key]
            self.stats.update_eviction()

    def _calculate_size(self, value: Any) -> int:
        """è®¡ç®—å€¼çš„å¤§å°"""
        try:
            if isinstance(value, str):
                return len(value.encode('utf-8'))
            elif isinstance(value, (dict, list)):
                return len(json.dumps(value, default=str).encode('utf-8'))
            elif isinstance(value, bytes):
                return len(value)
            else:
                # å…¶ä»–ç±»å‹çš„ä¼°ç®—
                return len(str(value).encode('utf-8'))
        except Exception:
            return 1024  # é»˜è®¤1KB

    def _update_memory_usage(self):
        """æ›´æ–°å†…å­˜ä½¿ç”¨ç»Ÿè®¡"""
        total_size = sum(
            entry.size_bytes for entry in self.memory_cache.values()
        )
        self.stats.memory_usage_bytes = total_size

    def _record_access_time(self, start_time: float):
        """è®°å½•è®¿é—®æ—¶é—´"""
        access_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        if self.stats.total_requests > 0:
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            alpha = 0.1  # å¹³æ»‘å› å­
            self.stats.avg_access_time_ms = (
                alpha * access_time +
                (1 - alpha) * self.stats.avg_access_time_ms
            )
        else:
            self.stats.avg_access_time_ms = access_time

    def _save_file_cache(self, cache_data: Dict):
        """ä¿å­˜æ–‡ä»¶ç¼“å­˜"""
        try:
            import os
            os.makedirs(os.path.dirname(self.file_cache_path), exist_ok=True)
            with open(self.file_cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            'total_requests': self.stats.total_requests,
            'cache_hits': self.stats.cache_hits,
            'cache_misses': self.stats.cache_misses,
            'hit_rate': self.stats.hit_rate,
            'evictions': self.stats.evictions,
            'memory_usage_bytes': self.stats.memory_usage_bytes,
            'memory_usage_mb': self.stats.memory_usage_bytes / (1024 * 1024),
            'avg_access_time_ms': self.stats.avg_access_time_ms,
            'memory_entries': len(self.memory_cache),
            'strategy': self.strategy.value,
            'redis_available': self.redis_cache is not None,
            'mongodb_available': self.mongodb_cache is not None
        }

    def optimize(self):
        """ä¼˜åŒ–ç¼“å­˜æ€§èƒ½"""
        logger.info("ğŸ”§ å¼€å§‹ç¼“å­˜ä¼˜åŒ–...")

        # 1. æ¸…ç†è¿‡æœŸæ¡ç›®
        expired_keys = [
            key for key, entry in self.memory_cache.items()
            if entry.is_expired()
        ]
        for key in expired_keys:
            del self.memory_cache[key]

        # 2. é‡æ–°æ’åºï¼ˆåŸºäºè®¿é—®é¢‘ç‡ï¼‰
        if self.strategy == CacheStrategy.LFU:
            sorted_entries = sorted(
                self.memory_cache.items(),
                key=lambda x: x[1].access_count,
                reverse=True
            )
            self.memory_cache = OrderedDict(sorted_entries)

        # 3. å†…å­˜ä½¿ç”¨ä¼˜åŒ–
        if self.stats.memory_usage_bytes > self.max_memory_size * 0.8:
            # é©±é€åˆ°80%ä»¥ä¸‹
            target_size = int(self.max_memory_size * 0.7)
            self._evict_entries(self.stats.memory_usage_bytes - target_size)

        self._update_memory_usage()
        logger.info(f"âœ… ç¼“å­˜ä¼˜åŒ–å®Œæˆ - æ¸…ç†è¿‡æœŸ: {len(expired_keys)} æ¡ç›®")