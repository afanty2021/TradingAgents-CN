#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç è´¨é‡æ£€æŸ¥è„šæœ¬
æ£€æŸ¥é¡¹ç›®ä¸­çš„ä»£ç è´¨é‡é—®é¢˜å¹¶æä¾›æ”¹è¿›å»ºè®®
"""

import os
import ast
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class CodeQualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self):
        self.project_root = project_root
        self.issues = []
        self.stats = {
            'files_checked': 0,
            'functions_with_types': 0,
            'functions_without_types': 0,
            'classes_with_docs': 0,
            'functions_with_docs': 0,
            'imports_star': 0,
            'complex_functions': 0,
            'lines_of_code': 0
        }

    def check_directory(self, directory: str) -> Dict[str, Any]:
        """æ£€æŸ¥ç›®å½•ä¸­çš„Pythonæ–‡ä»¶"""
        directory_path = self.project_root / directory
        if not directory_path.exists():
            return {'error': f'Directory {directory} not found'}

        for py_file in directory_path.rglob('*.py'):
            if '__pycache__' in str(py_file):
                continue
            self.check_file(py_file)

        return self.generate_report()

    def check_file(self, file_path: Path) -> None:
        """æ£€æŸ¥å•ä¸ªPythonæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # è§£æAST
            try:
                tree = ast.parse(content)
            except SyntaxError as e:
                self.issues.append({
                    'type': 'syntax_error',
                    'file': str(file_path),
                    'line': e.lineno,
                    'message': f'è¯­æ³•é”™è¯¯: {e.msg}'
                })
                return

            self.stats['files_checked'] += 1
            self.stats['lines_of_code'] += len(content.splitlines())

            # æ£€æŸ¥å„ç§è´¨é‡é—®é¢˜
            self.check_type_annotations(tree, file_path)
            self.check_docstrings(tree, file_path)
            self.check_imports(tree, file_path)
            self.check_complexity(tree, file_path, content)

        except Exception as e:
            self.issues.append({
                'type': 'file_error',
                'file': str(file_path),
                'message': f'æ–‡ä»¶æ£€æŸ¥é”™è¯¯: {str(e)}'
            })

    def check_type_annotations(self, tree: ast.AST, file_path: Path) -> None:
        """æ£€æŸ¥ç±»å‹æ³¨è§£"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                has_return_type = node.returns is not None
                has_param_types = all(
                    arg.annotation is not None
                    for arg in node.args.args
                )

                if has_return_type and has_param_types:
                    self.stats['functions_with_types'] += 1
                else:
                    self.stats['functions_without_types'] += 1
                    if not node.name.startswith('_'):  # å¿½ç•¥ç§æœ‰å‡½æ•°
                        self.issues.append({
                            'type': 'missing_type_annotation',
                            'file': str(file_path),
                            'line': node.lineno,
                            'function': node.name,
                            'message': f'å‡½æ•° {node.name} ç¼ºå°‘å®Œæ•´çš„ç±»å‹æ³¨è§£'
                        })

    def check_docstrings(self, tree: ast.AST, file_path: Path) -> None:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                if (ast.get_docstring(node) is not None and
                    len(ast.get_docstring(node).strip()) > 10):
                    self.stats['classes_with_docs'] += 1
                else:
                    self.issues.append({
                        'type': 'missing_class_docstring',
                        'file': str(file_path),
                        'line': node.lineno,
                        'class': node.name,
                        'message': f'ç±» {node.name} ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²'
                    })

            elif isinstance(node, ast.FunctionDef):
                if (ast.get_docstring(node) is not None and
                    len(ast.get_docstring(node).strip()) > 10):
                    self.stats['functions_with_docs'] += 1
                elif not node.name.startswith('_'):  # å¿½ç•¥ç§æœ‰å‡½æ•°
                    self.issues.append({
                        'type': 'missing_function_docstring',
                        'file': str(file_path),
                        'line': node.lineno,
                        'function': node.name,
                        'message': f'å‡½æ•° {node.name} ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²'
                    })

    def check_imports(self, tree: ast.AST, file_path: Path) -> None:
        """æ£€æŸ¥å¯¼å…¥è¯­å¥"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ImportFrom):
                if node.names[0].name == '*':
                    self.stats['imports_star'] += 1
                    self.issues.append({
                        'type': 'star_import',
                        'file': str(file_path),
                        'line': node.lineno,
                        'module': node.module or '',
                        'message': f'ä½¿ç”¨ import * è¿åä»£ç è§„èŒƒ'
                    })

    def check_complexity(self, tree: ast.AST, file_path: Path, content: str) -> None:
        """æ£€æŸ¥å‡½æ•°å¤æ‚åº¦"""
        lines = content.splitlines()

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # è®¡ç®—å‡½æ•°è¡Œæ•°
                func_lines = node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 0

                # ç®€å•çš„å¤æ‚åº¦æ£€æŸ¥ï¼šè¡Œæ•°è¶…è¿‡50è¡Œ
                if func_lines > 50:
                    self.stats['complex_functions'] += 1
                    self.issues.append({
                        'type': 'high_complexity',
                        'file': str(file_path),
                        'line': node.lineno,
                        'function': node.name,
                        'lines': func_lines,
                        'message': f'å‡½æ•° {node.name} è¿‡äºå¤æ‚ ({func_lines} è¡Œ)'
                    })

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        total_functions = self.stats['functions_with_types'] + self.stats['functions_without_types']
        type_coverage = (
            self.stats['functions_with_types'] / total_functions * 100
            if total_functions > 0 else 0
        )

        return {
            'timestamp': datetime.now().isoformat(),
            'statistics': self.stats,
            'quality_metrics': {
                'type_annotation_coverage': f'{type_coverage:.1f}%',
                'docstring_coverage': f'{self.stats["functions_with_docs"] / max(total_functions, 1) * 100:.1f}%',
                'star_imports': self.stats['imports_star'],
                'complex_functions': self.stats['complex_functions'],
                'avg_lines_per_file': self.stats['lines_of_code'] / max(self.stats['files_checked'], 1)
            },
            'issues': self.issues,
            'summary': {
                'total_issues': len(self.issues),
                'critical_issues': len([i for i in self.issues if i['type'] in ['syntax_error', 'file_error']]),
                'style_issues': len([i for i in self.issues if i['type'] in ['star_import', 'missing_type_annotation']]),
                'documentation_issues': len([i for i in self.issues if 'docstring' in i['type']]),
                'complexity_issues': len([i for i in self.issues if i['type'] == 'high_complexity'])
            }
        }

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·')
    parser.add_argument('--directory', '-d', default='tradingagents',
                       help='è¦æ£€æŸ¥çš„ç›®å½• (é»˜è®¤: tradingagents)')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')

    args = parser.parse_args()

    checker = CodeQualityChecker()
    report = checker.check_directory(args.directory)

    if args.json:
        output = json.dumps(report, ensure_ascii=False, indent=2)
    else:
        output = format_human_readable_report(report)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(output)
        print(f"âœ… è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(output)

def format_human_readable_report(report: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–äººç±»å¯è¯»çš„æŠ¥å‘Š"""
    output = []
    output.append("ğŸ“Š ä»£ç è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    output.append("=" * 50)
    output.append(f"æ£€æŸ¥æ—¶é—´: {report['timestamp']}")
    output.append("")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = report['statistics']
    output.append("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    output.append(f"  â€¢ æ£€æŸ¥æ–‡ä»¶æ•°: {stats['files_checked']}")
    output.append(f"  â€¢ æ€»ä»£ç è¡Œæ•°: {stats['lines_of_code']}")
    output.append(f"  â€¢ æœ‰ç±»å‹æ³¨è§£çš„å‡½æ•°: {stats['functions_with_types']}")
    output.append(f"  â€¢ æ— ç±»å‹æ³¨è§£çš„å‡½æ•°: {stats['functions_without_types']}")
    output.append(f"  â€¢ æœ‰æ–‡æ¡£å­—ç¬¦ä¸²çš„å‡½æ•°: {stats['functions_with_docs']}")
    output.append(f"  â€¢ æœ‰æ–‡æ¡£å­—ç¬¦ä¸²çš„ç±»: {stats['classes_with_docs']}")
    output.append("")

    # è´¨é‡æŒ‡æ ‡
    metrics = report['quality_metrics']
    output.append("ğŸ¯ è´¨é‡æŒ‡æ ‡:")
    output.append(f"  â€¢ ç±»å‹æ³¨è§£è¦†ç›–ç‡: {metrics['type_annotation_coverage']}")
    output.append(f"  â€¢ æ–‡æ¡£å­—ç¬¦ä¸²è¦†ç›–ç‡: {metrics['docstring_coverage']}")
    output.append(f"  â€¢ æ˜Ÿå·å¯¼å…¥æ•°é‡: {metrics['star_imports']}")
    output.append(f"  â€¢ å¤æ‚å‡½æ•°æ•°é‡: {metrics['complex_functions']}")
    output.append(f"  â€¢ å¹³å‡æ¯æ–‡ä»¶è¡Œæ•°: {metrics['avg_lines_per_file']:.1f}")
    output.append("")

    # é—®é¢˜æ‘˜è¦
    summary = report['summary']
    output.append("âš ï¸ é—®é¢˜æ‘˜è¦:")
    output.append(f"  â€¢ æ€»é—®é¢˜æ•°: {summary['total_issues']}")
    output.append(f"  â€¢ ä¸¥é‡é—®é¢˜: {summary['critical_issues']}")
    output.append(f"  â€¢ ä»£ç é£æ ¼é—®é¢˜: {summary['style_issues']}")
    output.append(f"  â€¢ æ–‡æ¡£é—®é¢˜: {summary['documentation_issues']}")
    output.append(f"  â€¢ å¤æ‚åº¦é—®é¢˜: {summary['complexity_issues']}")
    output.append("")

    # è¯¦ç»†é—®é¢˜åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªï¼‰
    issues = report['issues'][:20]
    if issues:
        output.append("ğŸ” è¯¦ç»†é—®é¢˜ (å‰20ä¸ª):")
        for issue in issues:
            file_path = Path(issue['file']).relative_to(project_root)
            output.append(f"  â€¢ {file_path}:{issue.get('line', '?')} - {issue['message']}")

    return "\n".join(output)

if __name__ == '__main__':
    main()