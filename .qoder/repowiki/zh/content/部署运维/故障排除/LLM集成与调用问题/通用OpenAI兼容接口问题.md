# é€šç”¨OpenAIå…¼å®¹æ¥å£é—®é¢˜æ’é™¤æŒ‡å—

<cite>
**æœ¬æ–‡æ¡£ä¸­å¼•ç”¨çš„æ–‡ä»¶**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py)
- [dashscope_openai_adapter.py](file://tradingagents/llm_adapters/dashscope_openai_adapter.py)
- [google_openai_adapter.py](file://tradingagents/llm_adapters/google_openai_adapter.py)
- [dashscope_adapter.py](file://tradingagents/llm_adapters/dashscope_adapter.py)
- [logging_manager.py](file://tradingagents/utils/logging_manager.py)
- [test_dashscope_adapter_fix.py](file://tests/test_dashscope_adapter_fix.py)
- [api_checker.py](file://web/utils/api_checker.py)
</cite>

## ç›®å½•
1. [ç®€ä»‹](#ç®€ä»‹)
2. [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
3. [æ ¸å¿ƒæŠ½è±¡åŸºç±»åˆ†æ](#æ ¸å¿ƒæŠ½è±¡åŸºç±»åˆ†æ)
4. [å¸¸è§é—®é¢˜è¯Šæ–­](#å¸¸è§é—®é¢˜è¯Šæ–­)
5. [é€‚é…å™¨ç»§æ‰¿æœºåˆ¶](#é€‚é…å™¨ç»§æ‰¿æœºåˆ¶)
6. [æ—¥å¿—è°ƒè¯•æŒ‡å—](#æ—¥å¿—è°ƒè¯•æŒ‡å—)
7. [æ¨¡æ‹Ÿæµ‹è¯•ç¯å¢ƒ](#æ¨¡æ‹Ÿæµ‹è¯•ç¯å¢ƒ)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
9. [æ•…éšœæ’é™¤æµç¨‹](#æ•…éšœæ’é™¤æµç¨‹)
10. [æ€»ç»“](#æ€»ç»“)

## ç®€ä»‹

æœ¬æ–‡æ¡£åŸºäºTradingAgentsé¡¹ç›®çš„`openai_compatible_base.py`æŠ½è±¡åŸºç±»ï¼Œä¸ºå¼€å‘è€…æä¾›é€šç”¨OpenAIå…¼å®¹æ¥å£é›†æˆçš„å®Œæ•´æ•…éšœæ’é™¤æŒ‡å—ã€‚è¯¥ç³»ç»Ÿæ”¯æŒå¤šä¸ªLLMæä¾›å•†ï¼ˆDeepSeekã€DashScopeã€Google AIã€åƒå¸†ç­‰ï¼‰ï¼Œé€šè¿‡ç»Ÿä¸€çš„é€‚é…å™¨æ¨¡å¼å®ç°æ ‡å‡†åŒ–çš„æ¥å£è°ƒç”¨ã€‚

## æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
subgraph "é€‚é…å™¨å±‚æ¬¡ç»“æ„"
Base[OpenAICompatibleBase<br/>æŠ½è±¡åŸºç±»]
DeepSeek[ChatDeepSeekOpenAI<br/>DeepSeeké€‚é…å™¨]
DashScope[ChatDashScopeOpenAI<br/>é˜¿é‡Œç™¾ç‚¼é€‚é…å™¨]
Google[ChatGoogleOpenAI<br/>Google AIé€‚é…å™¨]
Qianfan[ChatQianfanOpenAI<br/>åƒå¸†é€‚é…å™¨]
Custom[ChatCustomOpenAI<br/>è‡ªå®šä¹‰é€‚é…å™¨]
end
subgraph "å·¥å‚å‡½æ•°"
Factory[create_openai_compatible_llm<br/>ç»Ÿä¸€å·¥å‚å‡½æ•°]
end
subgraph "é…ç½®ç®¡ç†"
Config[OPENAI_COMPATIBLE_PROVIDERS<br/>æä¾›å•†é…ç½®]
end
Base --> DeepSeek
Base --> DashScope
Base --> Google
Base --> Qianfan
Base --> Custom
Factory --> Base
Config --> Factory
```

**å›¾è¡¨æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L31-L71)
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L381-L413)

**ç« èŠ‚æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L1-L436)

## æ ¸å¿ƒæŠ½è±¡åŸºç±»åˆ†æ

### OpenAICompatibleBaseç±»è®¾è®¡

`OpenAICompatibleBase`æ˜¯æ‰€æœ‰OpenAIå…¼å®¹é€‚é…å™¨çš„æŠ½è±¡åŸºç±»ï¼Œæä¾›äº†ç»Ÿä¸€çš„åˆå§‹åŒ–å’Œè¯·æ±‚å¤„ç†æœºåˆ¶ã€‚

#### æ ¸å¿ƒç‰¹æ€§

1. **ç»Ÿä¸€åˆå§‹åŒ–æµç¨‹**
   - APIå¯†é’¥è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è·å–
   - æ”¯æŒå¤šç§LangChainç‰ˆæœ¬çš„å…¼å®¹æ€§å¤„ç†
   - æä¾›è¯¦ç»†çš„åˆå§‹åŒ–æ—¥å¿—

2. **è¯·æ±‚å¤„ç†æœºåˆ¶**
   - è‡ªåŠ¨tokenä½¿ç”¨é‡è¿½è¸ª
   - ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
   - æ”¯æŒè‡ªå®šä¹‰å‚æ•°ä¼ é€’

#### å…³é”®æ–¹æ³•åˆ†æ

```mermaid
classDiagram
class OpenAICompatibleBase {
+provider_name : str
+model_name : str
+api_key : str
+base_url : str
+__init__(provider_name, model, api_key_env_var, base_url, ...)
+_generate(messages, stop, run_manager, **kwargs) ChatResult
+_track_token_usage(result, kwargs, start_time) void
+provider_name() str
}
class ChatDeepSeekOpenAI {
+__init__(model, api_key, temperature, max_tokens, **kwargs)
}
class ChatDashScopeOpenAIUnified {
+__init__(model, api_key, temperature, max_tokens, **kwargs)
}
class ChatQianfanOpenAI {
+__init__(model, api_key, temperature, max_tokens, **kwargs)
+_truncate_messages(messages, max_tokens) List[BaseMessage]
+_estimate_tokens(text) int
}
OpenAICompatibleBase <|-- ChatDeepSeekOpenAI
OpenAICompatibleBase <|-- ChatDashScopeOpenAIUnified
OpenAICompatibleBase <|-- ChatQianfanOpenAI
```

**å›¾è¡¨æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L31-L71)
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L138-L170)

**ç« èŠ‚æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L31-L170)

## å¸¸è§é—®é¢˜è¯Šæ–­

### HTTPçŠ¶æ€ç é”™è¯¯

#### 400 Bad Request
**ç—‡çŠ¶**: è¯·æ±‚æ ¼å¼é”™è¯¯ï¼ŒæœåŠ¡å™¨æ— æ³•ç†è§£

**å¸¸è§åŸå› **:
1. **è¯·æ±‚ä½“æ ¼å¼ä¸ç¬¦**
   - ç¼ºå°‘å¿…éœ€çš„å­—æ®µ
   - æ•°æ®ç±»å‹ä¸åŒ¹é…
   - å‚æ•°è¶…å‡ºèŒƒå›´

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼
def validate_request_format(messages, temperature, max_tokens):
    # éªŒè¯æ¶ˆæ¯æ ¼å¼
    if not isinstance(messages, list) or not messages:
        raise ValueError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    # éªŒè¯æ¸©åº¦å‚æ•°
    if not 0 <= temperature <= 2:
        raise ValueError("æ¸©åº¦å‚æ•°åº”åœ¨0-2èŒƒå›´å†…")
    
    # éªŒè¯æœ€å¤§tokenæ•°
    if max_tokens and max_tokens <= 0:
        raise ValueError("æœ€å¤§tokenæ•°å¿…é¡»å¤§äº0")
```

#### 401 Unauthorized
**ç—‡çŠ¶**: APIå¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤±

**è¯Šæ–­æ­¥éª¤**:
1. æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®
2. éªŒè¯APIå¯†é’¥æ ¼å¼
3. ç¡®è®¤å¯†é’¥æƒé™

**è§£å†³æ–¹æ¡ˆ**:
```python
# APIå¯†é’¥éªŒè¯å‡½æ•°
def validate_api_key(provider, api_key):
    if not api_key:
        raise ValueError(f"{provider} APIå¯†é’¥æœªæ‰¾åˆ°")
    
    # æ ¼å¼éªŒè¯
    if provider == "dashscope" and not api_key.startswith("sk-"):
        raise ValueError("é˜¿é‡Œç™¾ç‚¼APIå¯†é’¥åº”ä»¥'sk-'å¼€å¤´")
    elif provider == "qianfan" and not api_key.startswith("bce-v3/"):
        raise ValueError("åƒå¸†APIå¯†é’¥åº”ä»¥'bce-v3/'å¼€å¤´")
    
    return True
```

#### 404 Not Found
**ç—‡çŠ¶**: APIç«¯ç‚¹ä¸å­˜åœ¨æˆ–URLé”™è¯¯

**å¸¸è§åœºæ™¯**:
- è‡ªå®šä¹‰URLé…ç½®é”™è¯¯
- æä¾›å•†åŸŸåå˜æ›´
- æ¥å£ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
```python
# URLéªŒè¯å’Œä¿®å¤
def validate_base_url(base_url, provider):
    if not base_url:
        raise ValueError(f"{provider} åŸºç¡€URLä¸èƒ½ä¸ºç©º")
    
    # æ ‡å‡†åŒ–URLæ ¼å¼
    if not base_url.startswith(('http://', 'https://')):
        base_url = f"https://{base_url}"
    
    return base_url.rstrip('/')
```

#### 429 Rate Limit Exceeded
**ç—‡çŠ¶**: è¯·æ±‚é¢‘ç‡è¶…è¿‡é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**:
```python
# é€Ÿç‡é™åˆ¶å¤„ç†
import time
from functools import wraps

def rate_limited(max_per_second):
    def decorator(func):
        min_interval = 1.0 / max_per_second
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_time_called = getattr(wrapper, 'last_time_called', 0)
            elapsed = time.time() - last_time_called
            left_to_wait = min_interval - elapsed
            
            if left_to_wait > 0:
                time.sleep(left_to_wait)
            
            ret = func(*args, **kwargs)
            wrapper.last_time_called = time.time()
            return ret
        
        return wrapper
    
    return decorator
```

### è®¤è¯å¤´ç¼ºå¤±é—®é¢˜

#### ç¯å¢ƒå˜é‡é…ç½®é”™è¯¯
**ç—‡çŠ¶**: APIè°ƒç”¨æ—¶æç¤ºè®¤è¯å¤±è´¥

**è¯Šæ–­æ–¹æ³•**:
```python
# APIå¯†é’¥çŠ¶æ€æ£€æŸ¥
def check_api_key_status():
    required_keys = {
        "DASHSCOPE_API_KEY": "é˜¿é‡Œç™¾ç‚¼",
        "DEEPSEEK_API_KEY": "DeepSeek",
        "GOOGLE_API_KEY": "Google AI",
        "QIANFAN_API_KEY": "åƒå¸†"
    }
    
    missing_keys = []
    for env_var, provider in required_keys.items():
        if not os.getenv(env_var):
            missing_keys.append(provider)
    
    return {
        "has_missing_keys": bool(missing_keys),
        "missing_providers": missing_keys
    }
```

#### APIå¯†é’¥æ ¼å¼éªŒè¯
**å¸¸è§æ ¼å¼é—®é¢˜**:
- ç¼ºå°‘å‰ç¼€æ ‡è¯†
- æ ¼å¼ä¸å®Œæ•´
- åŒ…å«ç‰¹æ®Šå­—ç¬¦

**éªŒè¯è§„åˆ™**:
```python
# å¯†é’¥æ ¼å¼éªŒè¯
def validate_key_format(key_type, api_key):
    validations = {
        "DASHSCOPE_API_KEY": lambda k: k.startswith("sk-"),
        "DEEPSEEK_API_KEY": lambda k: len(k) > 10,
        "GOOGLE_API_KEY": lambda k: len(k) > 20,
        "QIANFAN_API_KEY": lambda k: k.startswith("bce-v3/")
    }
    
    if key_type in validations:
        if not validations[key_type](api_key):
            return False, f"{key_type} æ ¼å¼é”™è¯¯"
    
    return True, "æ ¼å¼æ­£ç¡®"
```

**ç« èŠ‚æ¥æº**
- [api_checker.py](file://web/utils/api_checker.py#L82-L132)
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L50-L70)

## é€‚é…å™¨ç»§æ‰¿æœºåˆ¶

### æ–¹æ³•é‡å†™è¦ç‚¹

#### `_generate`æ–¹æ³•é‡å†™
æ‰€æœ‰å­ç±»éƒ½éœ€è¦é‡å†™`_generate`æ–¹æ³•æ¥å¤„ç†ç‰¹å®šçš„è¯·æ±‚é€»è¾‘ï¼š

```python
def _generate(self, messages, stop=None, run_manager=None, **kwargs):
    # 1. è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–åŸºç¡€å“åº”
    result = super()._generate(messages, stop, run_manager, **kwargs)
    
    # 2. æ·»åŠ ç‰¹å®šçš„åå¤„ç†é€»è¾‘
    self._post_process_result(result)
    
    # 3. è®°å½•tokenä½¿ç”¨é‡
    self._track_token_usage(result, kwargs)
    
    return result
```

#### ç‰¹æ®Šé€‚é…å™¨çš„é‡å†™éœ€æ±‚

##### åƒå¸†æ¨¡å‹çš„tokenæˆªæ–­
```python
def _truncate_messages(self, messages, max_tokens=4500):
    """æˆªæ–­æ¶ˆæ¯ä»¥é€‚åº”åƒå¸†æ¨¡å‹çš„tokené™åˆ¶"""
    truncated_messages = []
    total_tokens = 0
    
    for message in reversed(messages):
        content = str(message.content)
        message_tokens = self._estimate_tokens(content)
        
        if total_tokens + message_tokens <= max_tokens:
            truncated_messages.insert(0, message)
            total_tokens += message_tokens
        else:
            # æˆªæ–­è¶…é•¿æ¶ˆæ¯
            if not truncated_messages:
                remaining_tokens = max_tokens - 100
                max_chars = remaining_tokens * 2
                truncated_content = content[:max_chars] + "...(å†…å®¹å·²æˆªæ–­)"
                message.content = truncated_content
                truncated_messages.insert(0, message)
            break
    
    return truncated_messages
```

##### Google AIçš„å·¥å…·è°ƒç”¨ä¼˜åŒ–
```python
def _optimize_message_content(self, message):
    """ä¼˜åŒ–æ¶ˆæ¯å†…å®¹æ ¼å¼ï¼Œç¡®ä¿åŒ…å«æ–°é—»ç‰¹å¾å…³é”®è¯"""
    if not isinstance(message, AIMessage) or not message.content:
        return
    
    content = message.content
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨è¿”å›çš„æ–°é—»å†…å®¹
    if self._is_news_content(content):
        optimized_content = self._enhance_news_content(content)
        message.content = optimized_content
```

### å·¥å‚å‡½æ•°è®¾è®¡

#### `create_openai_compatible_llm`å‡½æ•°
ç»Ÿä¸€çš„é€‚é…å™¨åˆ›å»ºå…¥å£ï¼Œæ”¯æŒåŠ¨æ€æä¾›å•†é€‰æ‹©ï¼š

```python
def create_openai_compatible_llm(
    provider: str,
    model: str,
    api_key: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: Optional[int] = None,
    base_url: Optional[str] = None,
    **kwargs
) -> OpenAICompatibleBase:
    """åˆ›å»ºOpenAIå…¼å®¹LLMå®ä¾‹çš„ç»Ÿä¸€å·¥å‚å‡½æ•°"""
    
    # 1. éªŒè¯æä¾›å•†æ”¯æŒ
    provider_info = OPENAI_COMPATIBLE_PROVIDERS.get(provider)
    if not provider_info:
        raise ValueError(f"ä¸æ”¯æŒçš„OpenAIå…¼å®¹æä¾›å•†: {provider}")
    
    # 2. å¤„ç†base_urlå‚æ•°å†²çª
    if base_url is None:
        base_url = provider_info.get("base_url")
    
    # 3. åˆ›å»ºé€‚é…å™¨å®ä¾‹
    adapter_class = provider_info["adapter_class"]
    return adapter_class(
        model=model,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        base_url=base_url,
        **kwargs
    )
```

**ç« èŠ‚æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L381-L413)
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L138-L170)

## æ—¥å¿—è°ƒè¯•æŒ‡å—

### ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ

ç³»ç»Ÿä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—ç®¡ç†å™¨ï¼Œæä¾›ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ—¥å¿—æ”¯æŒï¼š

```mermaid
graph LR
subgraph "æ—¥å¿—å¤„ç†å™¨"
Console[æ§åˆ¶å°å¤„ç†å™¨<br/>å½©è‰²è¾“å‡º]
File[æ–‡ä»¶å¤„ç†å™¨<br/>è½®è½¬æ—¥å¿—]
Structured[ç»“æ„åŒ–å¤„ç†å™¨<br/>JSONæ ¼å¼]
end
subgraph "æ—¥å¿—çº§åˆ«"
DEBUG[DEBUG<br/>è°ƒè¯•ä¿¡æ¯]
INFO[INFO<br/>ä¸€èˆ¬ä¿¡æ¯]
WARNING[WARNING<br/>è­¦å‘Šä¿¡æ¯]
ERROR[ERROR<br/>é”™è¯¯ä¿¡æ¯]
CRITICAL[CRITICAL<br/>ä¸¥é‡é”™è¯¯]
end
Console --> DEBUG
File --> INFO
Structured --> INFO
```

**å›¾è¡¨æ¥æº**
- [logging_manager.py](file://tradingagents/utils/logging_manager.py#L15-L40)
- [logging_manager.py](file://tradingagents/utils/logging_manager.py#L150-L200)

### è¯·æ±‚/å“åº”æ—¥å¿—è®°å½•

#### HTTPè¯·æ±‚æ—¥å¿—
```python
# è¯·æ±‚æ—¥å¿—è®°å½•
logger.info(
    f"ğŸ“¤ å‘é€è¯·æ±‚ - Provider: {provider}, Model: {model}",
    extra={
        'provider': provider,
        'model': model,
        'request_id': request_id,
        'timestamp': datetime.now().isoformat(),
        'request_body': sanitized_request
    }
)
```

#### å“åº”æ—¥å¿—è®°å½•
```python
# å“åº”æ—¥å¿—è®°å½•
logger.info(
    f"ğŸ“¥ æ¥æ”¶å“åº” - Status: {status_code}, Duration: {duration:.2f}s",
    extra={
        'provider': provider,
        'model': model,
        'status_code': status_code,
        'duration': duration,
        'response_size': len(response_text),
        'response_body': sanitized_response
    }
)
```

#### é”™è¯¯æ—¥å¿—è®°å½•
```python
# é”™è¯¯æ—¥å¿—è®°å½•
logger.error(
    f"âŒ APIè°ƒç”¨å¤±è´¥ - {error_type}: {error_message}",
    extra={
        'provider': provider,
        'model': model,
        'error_type': error_type,
        'error_details': error_details,
        'retry_count': retry_count,
        'backoff_time': backoff_time
    },
    exc_info=True
)
```

### è°ƒè¯•å·¥å…·å‡½æ•°

#### è¿æ¥æµ‹è¯•
```python
def test_api_connection(provider, model, api_key=None):
    """æµ‹è¯•APIè¿æ¥"""
    try:
        # åˆ›å»ºé€‚é…å™¨å®ä¾‹
        llm = create_openai_compatible_llm(
            provider=provider,
            model=model,
            api_key=api_key,
            max_tokens=50
        )
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        response = llm.invoke("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚")
        
        if response and hasattr(response, 'content') and response.content:
            logger.info(f"âœ… {provider} APIè¿æ¥æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ {provider} APIå“åº”ä¸ºç©º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {provider} APIè¿æ¥å¤±è´¥: {e}")
        return False
```

#### åŠŸèƒ½æµ‹è¯•
```python
def test_function_calling(provider, model, api_key=None):
    """æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½"""
    try:
        llm = create_openai_compatible_llm(
            provider=provider,
            model=model,
            api_key=api_key
        )
        
        # å®šä¹‰æµ‹è¯•å·¥å…·
        @tool
        def test_tool(query: str) -> str:
            return f"æ”¶åˆ°æŸ¥è¯¢: {query}"
        
        # ç»‘å®šå·¥å…·å¹¶æµ‹è¯•
        llm_with_tools = llm.bind_tools([test_tool])
        response = llm_with_tools.invoke("è¯·ä½¿ç”¨test_toolæŸ¥è¯¢'hello world'")
        
        if hasattr(response, 'tool_calls') and response.tool_calls:
            logger.info(f"âœ… {provider} å·¥å…·è°ƒç”¨åŠŸèƒ½æ­£å¸¸")
            return True
        else:
            logger.warning(f"âš ï¸ {provider} å·¥å…·è°ƒç”¨æœªè§¦å‘")
            return True  # å·¥å…·è°ƒç”¨æœªè§¦å‘ä¸ç®—å¤±è´¥
            
    except Exception as e:
        logger.error(f"âŒ {provider} å·¥å…·è°ƒç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False
```

**ç« èŠ‚æ¥æº**
- [logging_manager.py](file://tradingagents/utils/logging_manager.py#L1-L411)
- [dashscope_openai_adapter.py](file://tradingagents/llm_adapters/dashscope_openai_adapter.py#L180-L220)

## æ¨¡æ‹Ÿæµ‹è¯•ç¯å¢ƒ

### Mockæµ‹è¯•æ¡†æ¶

#### åŸºç¡€Mockç±»
```python
import unittest.mock as mock
from unittest import TestCase

class TestOpenAIAdapter(TestCase):
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.mock_llm = mock.MagicMock(spec=OpenAICompatibleBase)
        self.mock_llm.provider_name = "test_provider"
        self.mock_llm.model_name = "test-model"
        
        # æ¨¡æ‹ŸAPIå“åº”
        self.mock_response = mock.MagicMock()
        self.mock_response.content = "æµ‹è¯•å“åº”å†…å®¹"
        self.mock_response.tool_calls = []
        
        self.mock_llm.invoke.return_value = self.mock_response
    
    def test_basic_invoke(self):
        """æµ‹è¯•åŸºæœ¬è°ƒç”¨"""
        result = self.mock_llm.invoke("æµ‹è¯•æ¶ˆæ¯")
        self.assertEqual(result.content, "æµ‹è¯•å“åº”å†…å®¹")
        self.mock_llm.invoke.assert_called_once_with("æµ‹è¯•æ¶ˆæ¯")
```

#### å·¥å…·è°ƒç”¨Mock
```python
def mock_tool_calling_setup():
    """è®¾ç½®å·¥å…·è°ƒç”¨çš„Mock"""
    mock_tool_call = {
        "name": "get_stock_data",
        "arguments": '{"ticker": "AAPL", "days": 30}'
    }
    
    mock_response = mock.MagicMock()
    mock_response.content = "è‚¡ç¥¨æ•°æ®è·å–å®Œæˆ"
    mock_response.tool_calls = [mock_tool_call]
    
    return mock_response
```

### æµ‹è¯•æ•°æ®å‡†å¤‡

#### æ¨¡æ‹Ÿæ¶ˆæ¯æ ¼å¼
```python
def create_mock_messages():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„æ¶ˆæ¯æ ¼å¼"""
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    
    return [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆ"),
        HumanMessage(content="è¯·åˆ†æè‹¹æœå…¬å¸çš„è‚¡ç¥¨èµ°åŠ¿"),
        AIMessage(content="å¥½çš„ï¼Œè®©æˆ‘ä¸ºæ‚¨åˆ†æè‹¹æœå…¬å¸çš„è‚¡ç¥¨æ•°æ®")
    ]
```

#### æ¨¡æ‹ŸAPIå“åº”
```python
def create_mock_api_response(success=True, tool_calls=None):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„APIå“åº”"""
    if tool_calls is None:
        tool_calls = []
    
    mock_result = mock.MagicMock()
    mock_result.generations = [
        mock.MagicMock(
            message=mock.MagicMock(
                content="æµ‹è¯•å“åº”å†…å®¹" if success else "APIè°ƒç”¨å¤±è´¥",
                tool_calls=tool_calls
            )
        )
    ]
    
    return mock_result
```

### é›†æˆæµ‹è¯•ç¯å¢ƒ

#### ç¯å¢ƒéš”ç¦»
```python
@contextmanager
def isolated_test_environment():
    """åˆ›å»ºéš”ç¦»çš„æµ‹è¯•ç¯å¢ƒ"""
    original_env = os.environ.copy()
    original_modules = list(sys.modules.keys())
    
    try:
        # æ¸…ç†ç¯å¢ƒå˜é‡
        test_env_vars = ['TEST_API_KEY', 'TEST_BASE_URL']
        for var in test_env_vars:
            if var in os.environ:
                del os.environ[var]
        
        yield
        
    finally:
        # æ¢å¤åŸå§‹ç¯å¢ƒ
        os.environ.clear()
        os.environ.update(original_env)
        
        # æ¸…ç†æ–°å¢çš„æ¨¡å—
        for module in list(sys.modules.keys()):
            if module not in original_modules:
                del sys.modules[module]
```

**ç« èŠ‚æ¥æº**
- [test_dashscope_adapter_fix.py](file://tests/test_dashscope_adapter_fix.py#L1-L335)

## æœ€ä½³å®è·µ

### é”™è¯¯å¤„ç†ç­–ç•¥

#### åˆ†å±‚é”™è¯¯å¤„ç†
```python
def robust_api_call(provider, model, messages, max_retries=3):
    """å¥å£®çš„APIè°ƒç”¨å®ç°"""
    
    for attempt in range(max_retries):
        try:
            # 1. å‚æ•°éªŒè¯
            validate_input_parameters(messages, model)
            
            # 2. åˆ›å»ºé€‚é…å™¨
            llm = create_openai_compatible_llm(provider, model)
            
            # 3. æ‰§è¡Œè°ƒç”¨
            response = llm.invoke(messages)
            
            # 4. å“åº”éªŒè¯
            if validate_response(response):
                return response
            
            # 5. é‡è¯•é€»è¾‘
            if attempt < max_retries - 1:
                backoff_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                time.sleep(backoff_time)
                
        except ValueError as e:
            # å‚æ•°é”™è¯¯ï¼Œä¸é‡è¯•
            logger.error(f"å‚æ•°é”™è¯¯: {e}")
            raise
            
        except ConnectionError as e:
            # ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•
            logger.warning(f"ç½‘ç»œè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
            if attempt == max_retries - 1:
                raise
                
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œè®°å½•å¹¶é‡è¯•
            logger.error(f"æœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
            if attempt == max_retries - 1:
                raise
    
    raise TimeoutError("APIè°ƒç”¨è¶…æ—¶")
```

#### å¼‚å¸¸åˆ†ç±»å¤„ç†
```python
class APIException(Exception):
    """APIè°ƒç”¨å¼‚å¸¸åŸºç±»"""
    def __init__(self, provider, status_code, message):
        self.provider = provider
        self.status_code = status_code
        self.message = message
        super().__init__(f"{provider} APIé”™è¯¯ ({status_code}): {message}")

class AuthenticationError(APIException):
    """è®¤è¯é”™è¯¯"""
    pass

class RateLimitError(APIException):
    """é€Ÿç‡é™åˆ¶é”™è¯¯"""
    pass

class ValidationError(APIException):
    """è¯·æ±‚éªŒè¯é”™è¯¯"""
    pass
```

### æ€§èƒ½ä¼˜åŒ–

#### è¿æ¥æ± ç®¡ç†
```python
class APIClientPool:
    """APIå®¢æˆ·ç«¯è¿æ¥æ± """
    
    def __init__(self, max_pool_size=10):
        self.max_pool_size = max_pool_size
        self.pool = queue.Queue()
        self.active_connections = 0
    
    def get_client(self, provider, model):
        """è·å–å®¢æˆ·ç«¯è¿æ¥"""
        if self.pool.qsize() > 0:
            return self.pool.get()
        
        if self.active_connections < self.max_pool_size:
            self.active_connections += 1
            return create_openai_compatible_llm(provider, model)
        
        # ç­‰å¾…å¯ç”¨è¿æ¥
        return self.pool.get(timeout=30)
    
    def release_client(self, client):
        """é‡Šæ”¾å®¢æˆ·ç«¯è¿æ¥"""
        if self.pool.qsize() < self.max_pool_size:
            self.pool.put(client)
        else:
            # è¶…å‡ºæ± å¤§å°ï¼Œé”€æ¯è¿æ¥
            self.active_connections -= 1
```

#### ç¼“å­˜ç­–ç•¥
```python
class ResponseCache:
    """å“åº”ç¼“å­˜ç³»ç»Ÿ"""
    
    def __init__(self, ttl=300):  # 5åˆ†é’Ÿé»˜è®¤TTL
        self.cache = {}
        self.ttl = ttl
    
    def get(self, key):
        """è·å–ç¼“å­˜å€¼"""
        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                return value
            else:
                del self.cache[key]
        return None
    
    def set(self, key, value):
        """è®¾ç½®ç¼“å­˜å€¼"""
        self.cache[key] = (value, time.time())
```

### ç›‘æ§å’Œå‘Šè­¦

#### å…³é”®æŒ‡æ ‡ç›‘æ§
```python
class APIMonitor:
    """APIç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'average_response_time': 0,
            'error_rates': {}
        }
    
    def record_request(self, provider, success, duration, error_type=None):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.metrics['total_requests'] += 1
        
        if success:
            self.metrics['successful_requests'] += 1
        else:
            self.metrics['failed_requests'] += 1
            if error_type:
                self.metrics['error_rates'][error_type] = \
                    self.metrics['error_rates'].get(error_type, 0) + 1
        
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        current_avg = self.metrics['average_response_time']
        total_reqs = self.metrics['total_requests']
        self.metrics['average_response_time'] = \
            (current_avg * (total_reqs - 1) + duration) / total_reqs
    
    def get_health_status(self):
        """è·å–å¥åº·çŠ¶æ€"""
        total = self.metrics['total_requests']
        if total == 0:
            return "UNKNOWN"
        
        success_rate = self.metrics['successful_requests'] / total
        avg_time = self.metrics['average_response_time']
        
        if success_rate > 0.95 and avg_time < 5.0:
            return "HEALTHY"
        elif success_rate > 0.8:
            return "DEGRADED"
        else:
            return "UNHEALTHY"
```

## æ•…éšœæ’é™¤æµç¨‹

### è¯Šæ–­æµç¨‹å›¾

```mermaid
flowchart TD
Start([å¼€å§‹è¯Šæ–­]) --> CheckEnv["æ£€æŸ¥ç¯å¢ƒå˜é‡<br/>APIå¯†é’¥é…ç½®"]
CheckEnv --> EnvOK{"ç¯å¢ƒå˜é‡<br/>é…ç½®æ­£ç¡®?"}
EnvOK --> |å¦| FixEnv["ä¿®å¤ç¯å¢ƒå˜é‡<br/>é‡æ–°é…ç½®APIå¯†é’¥"]
EnvOK --> |æ˜¯| CheckNetwork["æ£€æŸ¥ç½‘ç»œè¿æ¥<br/>è®¿é—®æä¾›å•†API"]
CheckNetwork --> NetworkOK{"ç½‘ç»œè¿æ¥<br/>æ­£å¸¸?"}
NetworkOK --> |å¦| FixNetwork["æ£€æŸ¥ç½‘ç»œè®¾ç½®<br/>é˜²ç«å¢™é…ç½®"]
NetworkOK --> |æ˜¯| CheckAuth["éªŒè¯APIè®¤è¯<br/>å¯†é’¥æœ‰æ•ˆæ€§"]
CheckAuth --> AuthOK{"è®¤è¯<br/>é€šè¿‡?"}
AuthOK --> |å¦| FixAuth["æ›´æ–°APIå¯†é’¥<br/>æ£€æŸ¥æƒé™"]
AuthOK --> |æ˜¯| CheckRequest["æ£€æŸ¥è¯·æ±‚æ ¼å¼<br/>å‚æ•°éªŒè¯"]
CheckRequest --> RequestOK{"è¯·æ±‚æ ¼å¼<br/>æ­£ç¡®?"}
RequestOK --> |å¦| FixRequest["ä¿®æ­£è¯·æ±‚å‚æ•°<br/>æ ¼å¼è§„èŒƒ"]
RequestOK --> |æ˜¯| CheckResponse["åˆ†æå“åº”å†…å®¹<br/>é”™è¯¯ä¿¡æ¯"]
CheckResponse --> LogDebug["å¯ç”¨è°ƒè¯•æ—¥å¿—<br/>è¯¦ç»†åˆ†æ"]
LogDebug --> End([è¯Šæ–­å®Œæˆ])
FixEnv --> CheckNetwork
FixNetwork --> CheckAuth
FixAuth --> CheckRequest
FixRequest --> CheckResponse
```

### é—®é¢˜åˆ†ç±»è¡¨

| é—®é¢˜ç±»å‹ | ç—‡çŠ¶æè¿° | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|---------|
| è®¤è¯å¤±è´¥ | 401é”™è¯¯ï¼ŒAPIå¯†é’¥æ— æ•ˆ | ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå¯†é’¥æ ¼å¼é”™è¯¯ | æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ŒéªŒè¯å¯†é’¥æ ¼å¼ |
| ç½‘ç»œè¿æ¥ | è¿æ¥è¶…æ—¶ï¼ŒDNSè§£æå¤±è´¥ | ç½‘ç»œä¸é€šï¼Œé˜²ç«å¢™é˜»æ­¢ | æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œé…ç½®ä»£ç† |
| è¯·æ±‚æ ¼å¼ | 400é”™è¯¯ï¼Œå‚æ•°éªŒè¯å¤±è´¥ | æ¶ˆæ¯æ ¼å¼ä¸æ­£ç¡®ï¼Œå‚æ•°ç±»å‹é”™è¯¯ | éªŒè¯æ¶ˆæ¯ç»“æ„ï¼Œæ£€æŸ¥å‚æ•°ç±»å‹ |
| é€Ÿç‡é™åˆ¶ | 429é”™è¯¯ï¼Œè¯·æ±‚è¿‡äºé¢‘ç¹ | è¶…å‡ºAPIé…é¢ï¼Œè¯·æ±‚é¢‘ç‡è¿‡é«˜ | å®ç°æŒ‡æ•°é€€é¿ï¼Œé™ä½è¯·æ±‚é¢‘ç‡ |
| æ¨¡å‹ä¸å¯ç”¨ | 404é”™è¯¯ï¼Œæ¨¡å‹ä¸å­˜åœ¨ | æ¨¡å‹åç§°é”™è¯¯ï¼Œæƒé™ä¸è¶³ | æ£€æŸ¥æ¨¡å‹åˆ—è¡¨ï¼Œç¡®è®¤æƒé™ |
| å·¥å…·è°ƒç”¨å¤±è´¥ | Function callingå¤±è´¥ | å·¥å…·å®šä¹‰æ ¼å¼é”™è¯¯ï¼Œå‚æ•°ä¸åŒ¹é… | éªŒè¯å·¥å…·å®šä¹‰ï¼Œæ£€æŸ¥å‚æ•°æ ¼å¼ |

### è°ƒè¯•æ£€æŸ¥æ¸…å•

#### åŸºç¡€æ£€æŸ¥
- [ ] ç¯å¢ƒå˜é‡å·²æ­£ç¡®è®¾ç½®
- [ ] APIå¯†é’¥æ ¼å¼æ­£ç¡®
- [ ] ç½‘ç»œè¿æ¥æ­£å¸¸
- [ ] åŸºç¡€URLé…ç½®æ­£ç¡®

#### è¯·æ±‚æ£€æŸ¥
- [ ] æ¶ˆæ¯æ ¼å¼ç¬¦åˆOpenAIè§„èŒƒ
- [ ] å‚æ•°ç±»å‹å’ŒèŒƒå›´æ­£ç¡®
- [ ] å·¥å…·å®šä¹‰æ ¼å¼æ­£ç¡®
- [ ] è¯·æ±‚ä½“å¤§å°åœ¨é™åˆ¶å†…

#### å“åº”æ£€æŸ¥
- [ ] HTTPçŠ¶æ€ç æ­£å¸¸
- [ ] å“åº”å†…å®¹æ ¼å¼æ­£ç¡®
- [ ] tokenä½¿ç”¨é‡åˆç†
- [ ] é”™è¯¯ä¿¡æ¯æ¸…æ™°æ˜ç¡®

**ç« èŠ‚æ¥æº**
- [openai_compatible_base.py](file://tradingagents/llm_adapters/openai_compatible_base.py#L413-L434)

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†åŸºäº`openai_compatible_base.py`æŠ½è±¡åŸºç±»çš„å®Œæ•´OpenAIå…¼å®¹æ¥å£æ•…éšœæ’é™¤æŒ‡å—ã€‚é€šè¿‡ç³»ç»ŸåŒ–çš„è¯Šæ–­æµç¨‹ã€è¯¦ç»†çš„é”™è¯¯å¤„ç†ç­–ç•¥å’Œå®ç”¨çš„è°ƒè¯•å·¥å…·ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿå®šä½å’Œè§£å†³é›†æˆè¿‡ç¨‹ä¸­é‡åˆ°çš„å„ç§é—®é¢˜ã€‚

### å…³é”®è¦ç‚¹

1. **ç»Ÿä¸€çš„æŠ½è±¡åŸºç±»è®¾è®¡**ï¼š`OpenAICompatibleBase`æä¾›äº†æ ‡å‡†åŒ–çš„åˆå§‹åŒ–å’Œè¯·æ±‚å¤„ç†æœºåˆ¶
2. **åˆ†å±‚çš„é”™è¯¯å¤„ç†**ï¼šä»ç½‘ç»œå±‚åˆ°åº”ç”¨å±‚çš„å…¨é¢é”™è¯¯æ•è·å’Œå¤„ç†
3. **å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿ**ï¼šç»“æ„åŒ–å’Œéç»“æ„åŒ–æ—¥å¿—æ”¯æŒï¼Œä¾¿äºé—®é¢˜è¿½è¸ª
4. **çµæ´»çš„é€‚é…å™¨æœºåˆ¶**ï¼šæ”¯æŒä¸åŒæä¾›å•†çš„ç‰¹æ®Šéœ€æ±‚å’Œä¼˜åŒ–
5. **å¼ºå¤§çš„æµ‹è¯•æ¡†æ¶**ï¼šæä¾›æ¨¡æ‹Ÿæµ‹è¯•å’Œé›†æˆæµ‹è¯•èƒ½åŠ›

### æœ€ä½³å®è·µå»ºè®®

1. **å§‹ç»ˆä½¿ç”¨å·¥å‚å‡½æ•°**ï¼šé€šè¿‡`create_openai_compatible_llm`åˆ›å»ºé€‚é…å™¨å®ä¾‹
2. **å®æ–½åˆ†å±‚é”™è¯¯å¤„ç†**ï¼šåœ¨åº”ç”¨å±‚æ•è·å’Œå¤„ç†ç‰¹å®šå¼‚å¸¸
3. **å¯ç”¨è¯¦ç»†æ—¥å¿—**ï¼šåœ¨å¼€å‘é˜¶æ®µå¯ç”¨è°ƒè¯•æ—¥å¿—ï¼Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
4. **å®šæœŸè¿›è¡Œå¥åº·æ£€æŸ¥**ï¼šç›‘æ§APIè°ƒç”¨çš„æˆåŠŸç‡å’Œå“åº”æ—¶é—´
5. **å»ºç«‹æµ‹è¯•ç¯å¢ƒ**ï¼šä½¿ç”¨æ¨¡æ‹Ÿæµ‹è¯•ç¡®ä¿ä»£ç è´¨é‡

é€šè¿‡éµå¾ªæœ¬æ–‡æ¡£æä¾›çš„æŒ‡å¯¼åŸåˆ™å’Œæœ€ä½³å®è·µï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºç¨³å®šå¯é çš„OpenAIå…¼å®¹æ¥å£é›†æˆï¼Œç¡®ä¿ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§å’Œè‰¯å¥½çš„ç”¨æˆ·ä½“éªŒã€‚