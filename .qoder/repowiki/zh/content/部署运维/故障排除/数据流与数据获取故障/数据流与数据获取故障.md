# 数据流与数据获取故障排除指南

<cite>
**本文档引用的文件**
- [diagnose_empty_data.py](file://scripts/diagnose_empty_data.py)
- [test_fundamentals_with_stock_name.py](file://scripts/test_fundamentals_with_stock_name.py)
- [stock_code_validator.py](file://scripts/stock_code_validator.py)
- [akshare_utils.py](file://tradingagents/dataflows/akshare_utils.py)
- [finnhub_utils.py](file://tradingagents/dataflows/finnhub_utils.py)
- [data_source_manager.py](file://tradingagents/dataflows/data_source_manager.py)
- [tushare_adapter.py](file://tradingagents/dataflows/tushare_adapter.py)
- [cache_manager.py](file://tradingagents/dataflows/cache_manager.py)
- [db_cache_manager.py](file://tradingagents/dataflows/db_cache_manager.py)
- [config_manager.py](file://tradingagents/config/config_manager.py)
- [default_config.py](file://tradingagents/default_config.py)
</cite>

## 目录
1. [概述](#概述)
2. [核心诊断工具](#核心诊断工具)
3. [数据源架构与降级机制](#数据源架构与降级机制)
4. [错误处理与重试策略](#错误处理与重试策略)
5. [缓存系统故障排除](#缓存系统故障排除)
6. [配置管理与环境设置](#配置管理与环境设置)
7. [常见故障模式与解决方案](#常见故障模式与解决方案)
8. [性能优化建议](#性能优化建议)
9. [监控与日志分析](#监控与日志分析)
10. [故障排除工作流程](#故障排除工作流程)

## 概述

TradingAgents-CN系统采用多层数据获取架构，支持多个数据源的自动切换和降级机制。本指南涵盖从数据管道中断检测到系统恢复的完整故障排除流程。

### 系统架构概览

```mermaid
graph TB
subgraph "用户接口层"
CLI[命令行接口]
Web[Web界面]
API[API服务]
end
subgraph "数据源管理层"
DSM[数据源管理器]
DSC[降级策略控制器]
end
subgraph "数据源适配器层"
TA[Tushare适配器]
AA[AKShare适配器]
BA[BaoStock适配器]
FA[FinnHub适配器]
end
subgraph "缓存层"
CM[本地缓存]
DBC[数据库缓存]
RC[Redis缓存]
end
subgraph "外部数据源"
TS[Tushare API]
AS[AKShare库]
BS[BaoStock库]
FH[FinnHub API]
end
CLI --> DSM
Web --> DSM
API --> DSM
DSM --> TA
DSM --> AA
DSM --> BA
DSM --> FA
TA --> TS
AA --> AS
BA --> BS
FA --> FH
DSM --> CM
DSM --> DBC
DSM --> RC
```

**图表来源**
- [data_source_manager.py](file://tradingagents/dataflows/data_source_manager.py#L1-L50)
- [tushare_adapter.py](file://tradingagents/dataflows/tushare_adapter.py#L1-L50)

## 核心诊断工具

### diagnose_empty_data.py - 空数据诊断工具

该工具专门用于诊断Tushare返回空数据的各种原因，提供系统性的排查方法。

#### 主要诊断功能

1. **时间参数测试**：验证不同时间范围的数据获取能力
2. **股票代码验证**：测试不同类型股票代码的兼容性
3. **API限制检查**：评估API调用频率和权限限制
4. **日期格式验证**：确认支持的日期格式

#### 诊断流程图

```mermaid
flowchart TD
Start([开始诊断]) --> TestTime["测试时间参数<br/>不同日期范围"]
TestTime --> TestCodes["测试股票代码<br/>多种类型验证"]
TestCodes --> TestAPI["测试API限制<br/>权限和频率"]
TestAPI --> TestFormats["测试日期格式<br/>YYYY-MM-DD vs YYYYMMDD"]
TestFormats --> Summary["生成诊断报告"]
TestTime --> TimeResult{"时间参数有效?"}
TimeResult --> |否| TimeFix["调整时间范围"]
TimeResult --> |是| CodesTest
TestCodes --> CodeResult{"股票代码有效?"}
CodeResult --> |否| CodeFix["修正股票代码"]
CodeResult --> |是| APITest
TestAPI --> APIResult{"API权限充足?"}
APIResult --> |否| APIFix["检查API配置"]
APIResult --> |是| FormatTest
TestFormats --> FormatResult{"日期格式正确?"}
FormatResult --> |否| FormatFix["转换日期格式"]
FormatResult --> |是| Summary
```

**图表来源**
- [diagnose_empty_data.py](file://scripts/diagnose_empty_data.py#L15-L100)

**章节来源**
- [diagnose_empty_data.py](file://scripts/diagnose_empty_data.py#L1-L250)

### test_fundamentals_with_stock_name.py - 基本面数据验证工具

此工具验证基本面分析中的股票名称获取功能，确保数据源能够正确识别和显示股票信息。

#### 验证步骤

1. **股票数据获取测试**：验证基本数据获取能力
2. **基本面报告生成**：测试报告生成功能
3. **股票名称提取**：确认股票名称正确显示
4. **降级机制测试**：验证备用数据源切换

**章节来源**
- [test_fundamentals_with_stock_name.py](file://scripts/test_fundamentals_with_stock_name.py#L1-L200)

### stock_code_validator.py - 股票代码校验器

提供股票代码的自动修正功能，处理常见的输入错误。

#### 校验逻辑

```mermaid
flowchart TD
Input[输入股票代码] --> Validate["验证代码格式"]
Validate --> CheckError{"是否在错误映射中?"}
CheckError --> |是| GetMapping["获取错误映射"]
CheckError --> |否| ReturnOriginal["返回原始代码"]
GetMapping --> ReplaceCode["替换为正确代码"]
ReplaceCode --> LogError["记录错误日志"]
LogError --> ReturnFixed["返回修正代码"]
ReturnOriginal --> End([结束])
ReturnFixed --> End
```

**图表来源**
- [stock_code_validator.py](file://scripts/stock_code_validator.py#L10-L35)

**章节来源**
- [stock_code_validator.py](file://scripts/stock_code_validator.py#L1-L35)

## 数据源架构与降级机制

### 数据源管理器架构

系统采用多数据源并行架构，支持自动降级和负载均衡。

#### 数据源优先级

```mermaid
graph LR
subgraph "首选数据源"
AK[AKShare]
end
subgraph "备用数据源"
TS[Tushare]
BS[BaoStock]
end
subgraph "降级数据源"
FA[FinnHub]
YF[YFinance]
end
AK --> TS
TS --> BS
BS --> FA
FA --> YF
```

**图表来源**
- [data_source_manager.py](file://tradingagents/dataflows/data_source_manager.py#L20-L30)

#### 降级机制实现

系统实现了智能降级机制，当主数据源失败时自动切换到备用数据源。

```mermaid
sequenceDiagram
participant Client as 客户端
participant DSM as 数据源管理器
participant Primary as 主数据源
participant Backup as 备用数据源
participant Cache as 缓存系统
Client->>DSM : 请求股票数据
DSM->>Primary : 尝试获取数据
Primary-->>DSM : 失败/超时
DSM->>DSM : 检查降级条件
DSM->>Backup : 切换到备用数据源
Backup-->>DSM : 返回数据
DSM->>Cache : 缓存结果
DSM-->>Client : 返回最终结果
Note over DSM,Backup : 自动降级，无需人工干预
```

**图表来源**
- [data_source_manager.py](file://tradingagents/dataflows/data_source_manager.py#L340-L380)

**章节来源**
- [data_source_manager.py](file://tradingagents/dataflows/data_source_manager.py#L1-L856)

### 数据适配器错误处理

#### AKShare适配器错误处理

AKShare适配器实现了完善的错误处理和超时控制机制。

##### 超时配置

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| 超时时间 | 60秒 | 单次API调用最大等待时间 |
| 重试次数 | 3次 | 连接失败时的重试次数 |
| 退避策略 | 指数退避 | 重试间隔逐渐增加 |
| 状态码重试 | 429, 500, 502, 503, 504 | 支持的重试HTTP状态码 |

##### 错误处理流程

```mermaid
flowchart TD
APICall[API调用] --> CheckResponse{"响应状态"}
CheckResponse --> |成功| ProcessData["处理数据"]
CheckResponse --> |超时| HandleTimeout["处理超时"]
CheckResponse --> |错误| HandleError["处理错误"]
HandleTimeout --> CheckRetry{"可重试?"}
CheckRetry --> |是| WaitBackoff["指数退避等待"]
CheckRetry --> |否| SwitchSource["切换数据源"]
WaitBackoff --> RetryAPICall["重试API调用"]
RetryAPICall --> APICall
HandleError --> LogError["记录错误日志"]
LogError --> SwitchSource
SwitchSource --> NextSource["尝试下一个数据源"]
NextSource --> APICall
ProcessData --> ReturnData["返回数据"]
```

**图表来源**
- [akshare_utils.py](file://tradingagents/dataflows/akshare_utils.py#L40-L70)

**章节来源**
- [akshare_utils.py](file://tradingagents/dataflows/akshare_utils.py#L1-L632)

#### Finnhub适配器错误处理

FinnHub适配器专注于文件系统数据的错误处理。

##### 文件读取错误处理

| 错误类型 | 处理策略 | 日志级别 |
|----------|----------|----------|
| 文件不存在 | 跳过并记录警告 | WARNING |
| JSON解析错误 | 返回空字典 | ERROR |
| 读取权限错误 | 记录错误并返回空 | ERROR |
| 数据范围过滤 | 返回过滤后的数据 | INFO |

**章节来源**
- [finnhub_utils.py](file://tradingagents/dataflows/finnhub_utils.py#L1-L57)

## 错误处理与重试策略

### 超时与重试机制

系统实现了多层次的超时和重试机制，确保数据获取的可靠性。

#### 超时配置层次

```mermaid
graph TD
subgraph "应用层超时"
APP[应用级超时<br/>30秒]
end
subgraph "网络层超时"
NET[网络层超时<br/>60秒]
end
subgraph "API层超时"
API[API层超时<br/>30秒]
end
subgraph "数据库层超时"
DB[数据库超时<br/>5秒]
end
APP --> NET
NET --> API
API --> DB
```

#### 重试策略配置

| 数据源 | 重试次数 | 退避策略 | 最大等待时间 |
|--------|----------|----------|--------------|
| Tushare | 3次 | 指数退避 | 16秒 |
| AKShare | 3次 | 线性退避 | 15秒 |
| Finnhub | 2次 | 固定间隔 | 10秒 |
| 数据库 | 3次 | 指数退避 | 30秒 |

### 错误分类与处理

#### 网络错误

```mermaid
flowchart TD
NetworkError[网络错误] --> CheckType{"错误类型"}
CheckType --> |连接超时| TimeoutHandler["超时处理器"]
CheckType --> |DNS解析| DNSHandler["DNS处理器"]
CheckType --> |SSL证书| SSLHandler["SSL处理器"]
CheckType --> |网络中断| NetworkHandler["网络处理器"]
TimeoutHandler --> RetryLogic["重试逻辑"]
DNSHandler --> RetryLogic
SSLHandler --> RetryLogic
NetworkHandler --> RetryLogic
RetryLogic --> MaxRetries{"达到最大重试?"}
MaxRetries --> |否| BackoffWait["退避等待"]
MaxRetries --> |是| FallbackSource["降级到备用数据源"]
BackoffWait --> RetryLogic
```

#### 数据错误

| 错误类型 | 检测方法 | 处理策略 | 恢复措施 |
|----------|----------|----------|----------|
| 空数据返回 | 数据帧为空检查 | 降级到备用数据源 | 切换数据源 |
| 数据格式错误 | 列名验证 | 数据标准化 | 标准化处理 |
| 数据完整性缺失 | 关键列检查 | 补充默认值 | 填充默认值 |
| API限流 | HTTP状态码检查 | 等待重试 | 指数退避 |

**章节来源**
- [tushare_adapter.py](file://tradingagents/dataflows/tushare_adapter.py#L1-L493)

## 缓存系统故障排除

### 本地缓存管理

系统提供了两级缓存架构：内存缓存和磁盘缓存。

#### 缓存配置层次

```mermaid
graph TB
subgraph "内存缓存层"
MC[MongoDB缓存<br/>Redis缓存]
end
subgraph "磁盘缓存层"
DC[本地文件缓存<br/>数据库缓存]
end
subgraph "缓存策略"
TTL[生存时间控制]
LRU[LRU淘汰策略]
SIZE[大小限制]
end
MC --> DC
DC --> TTL
DC --> LRU
DC --> SIZE
```

**图表来源**
- [cache_manager.py](file://tradingagents/dataflows/cache_manager.py#L40-L80)
- [db_cache_manager.py](file://tradingagents/dataflows/db_cache_manager.py#L40-L80)

#### 缓存失效检测

```mermaid
sequenceDiagram
participant Client as 客户端
participant Cache as 缓存系统
participant Validator as 缓存验证器
participant Cleaner as 缓存清理器
Client->>Cache : 请求数据
Cache->>Validator : 检查缓存有效性
Validator->>Validator : 验证TTL
Validator->>Validator : 检查数据完整性
Validator-->>Cache : 缓存状态
Cache-->>Client : 返回数据/触发刷新
alt 缓存过期
Cache->>Cleaner : 标记过期
Cleaner->>Cleaner : 清理过期缓存
end
```

**图表来源**
- [cache_manager.py](file://tradingagents/dataflows/cache_manager.py#L200-L250)

#### 缓存统计与监控

| 指标 | 描述 | 正常范围 |
|------|------|----------|
| 命中率 | 缓存命中次数/总请求次数 | >80% |
| 平均响应时间 | 缓存查询平均耗时 | <100ms |
| 存储空间使用率 | 缓存占用磁盘空间比例 | <90% |
| 过期数据比例 | 已过期但未清理的数据比例 | <5% |

**章节来源**
- [cache_manager.py](file://tradingagents/dataflows/cache_manager.py#L1-L647)
- [db_cache_manager.py](file://tradingagents/dataflows/db_cache_manager.py#L1-L534)

## 配置管理与环境设置

### 配置文件结构

系统采用分层配置管理，支持环境变量覆盖和配置文件优先级。

#### 配置优先级

```mermaid
graph TD
Env[环境变量] --> Config[配置文件]
Config --> Defaults[默认配置]
Env --> EnvVars["API密钥<br/>端口配置<br/>功能开关"]
Config --> JsonFiles["models.json<br/>pricing.json<br/>settings.json"]
Defaults --> BaseConfig["基础配置<br/>默认值<br/>路径设置"]
```

**图表来源**
- [config_manager.py](file://tradingagents/config/config_manager.py#L100-L150)

#### 关键配置项

| 配置类别 | 关键参数 | 默认值 | 说明 |
|----------|----------|--------|------|
| 数据源 | DEFAULT_CHINA_DATA_SOURCE | akshare | 默认中国股市数据源 |
| 缓存 | MAX_CACHE_CONTENT_LENGTH | 50000 | 缓存内容最大长度 |
| 超时 | REQUEST_TIMEOUT | 30 | HTTP请求超时时间 |
| 重试 | MAX_RETRIES | 3 | API调用最大重试次数 |
| 日志 | LOG_LEVEL | INFO | 日志级别设置 |

### 环境变量配置

#### API密钥配置

```bash
# OpenAI配置
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_ENABLED=true

# DashScope配置
DASHSCOPE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Finnhub配置
FINNHUB_API_KEY=xxxxxxxxxxxxxxxxxxxxxx

# MongoDB配置
MONGODB_URL=mongodb://admin:password@localhost:27018
MONGODB_PASSWORD=tradingagents123

# Redis配置
REDIS_URL=redis://:password@localhost:6380
REDIS_PASSWORD=tradingagents123
```

#### 功能开关配置

```bash
# 数据源功能开关
ONLINE_NEWS_ENABLED=true
REALTIME_DATA_ENABLED=false
ONLINE_TOOLS_ENABLED=false

# 缓存功能开关
ENABLE_CACHE_LENGTH_CHECK=true

# 日志配置
TRADINGAGENTS_LOG_LEVEL=INFO
TRADINGAGENTS_RESULTS_DIR=./results
```

**章节来源**
- [config_manager.py](file://tradingagents/config/config_manager.py#L1-L727)
- [default_config.py](file://tradingagents/default_config.py#L1-L28)

## 常见故障模式与解决方案

### 数据获取失败模式

#### 模式1：API认证失败

**症状表现**：
- 返回401/403 HTTP状态码
- "Invalid API key"错误信息
- 数据源连接失败日志

**诊断步骤**：
1. 检查API密钥格式和有效性
2. 验证账户余额和配额
3. 确认API权限设置

**解决方案**：
```python
# 检查API密钥配置
from tradingagents.config.config_manager import config_manager
status = config_manager.get_env_config_status()
print(status['api_keys'])

# 验证OpenAI密钥格式
from tradingagents.config.config_manager import ConfigManager
config = ConfigManager()
openai_status = config.get_openai_config_status()
print(openai_status)
```

#### 模式2：网络连接超时

**症状表现**：
- 请求超时异常
- 网络不可达错误
- DNS解析失败

**诊断步骤**：
1. 检查网络连接状态
2. 验证防火墙设置
3. 测试DNS解析

**解决方案**：
```python
# 调整超时配置
import os
os.environ['REQUEST_TIMEOUT'] = '60'  # 增加超时时间
os.environ['NETWORK_RETRY_COUNT'] = '5'  # 增加重试次数
```

#### 模式3：数据格式不兼容

**症状表现**：
- KeyError异常
- 列名不匹配
- 数据类型转换错误

**诊断步骤**：
1. 检查数据源返回格式
2. 验证列名映射关系
3. 确认数据类型兼容性

**解决方案**：
```python
# 使用数据标准化功能
from tradingagents.dataflows.tushare_adapter import TushareDataAdapter
adapter = TushareDataAdapter(enable_cache=False)
data = adapter.get_stock_data('000001', '2024-01-01', '2024-12-31')
standardized_data = adapter._validate_and_standardize_data(data)
```

### 缓存系统故障

#### 缓存写入失败

**症状表现**：
- 缓存文件创建失败
- 磁盘空间不足
- 权限拒绝错误

**诊断步骤**：
1. 检查磁盘空间
2. 验证目录权限
3. 确认缓存配置

**解决方案**：
```python
# 清理缓存并重建
from tradingagents.dataflows.cache_manager import get_cache
cache = get_cache()
cache.clear_old_cache(max_age_days=1)
cache.ensure_directories_exist()
```

#### 缓存读取失败

**症状表现**：
- 缓存文件损坏
- JSON解析错误
- 数据格式不匹配

**诊断步骤**：
1. 检查缓存文件完整性
2. 验证JSON格式
3. 确认数据格式

**解决方案**：
```python
# 修复缓存文件
from tradingagents.dataflows.cache_manager import get_cache
cache = get_cache()
cache.clear_corrupted_cache()
```

### 数据源切换故障

#### 切换逻辑失效

**症状表现**：
- 降级机制未触发
- 数据源切换失败
- 循环调用错误

**诊断步骤**：
1. 检查数据源可用性
2. 验证降级逻辑
3. 确认超时设置

**解决方案**：
```python
# 手动切换数据源
from tradingagents.dataflows.data_source_manager import get_data_source_manager
manager = get_data_source_manager()
manager.set_current_source(ChinaDataSource.AKSHARE)

# 测试降级机制
result = manager._try_fallback_sources('000001', '2024-01-01', '2024-12-31')
```

## 性能优化建议

### 数据获取优化

#### 并发处理优化

```mermaid
graph LR
subgraph "并发策略"
Pool[线程池]
Queue[任务队列]
Monitor[监控器]
end
subgraph "优化技术"
Batch[批量处理]
Prefetch[预取机制]
Compression[压缩传输]
end
Pool --> Batch
Queue --> Prefetch
Monitor --> Compression
```

#### 性能调优参数

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| 并发线程数 | CPU核数×2 | 最大并发请求数 |
| 批量大小 | 100-500 | 单次批量处理股票数量 |
| 预取窗口 | 5-10分钟 | 预取未来数据的时间窗口 |
| 缓存预热 | 启用 | 启动时预加载常用数据 |

### 缓存优化策略

#### 缓存策略优化

```mermaid
flowchart TD
Request[数据请求] --> CheckCache{"缓存命中?"}
CheckCache --> |命中| ReturnCached["返回缓存数据"]
CheckCache --> |未命中| CheckSize{"数据大小"}
CheckSize --> |小数据| DirectFetch["直接获取"]
CheckSize --> |大数据| AsyncFetch["异步获取"]
DirectFetch --> UpdateCache["更新缓存"]
AsyncFetch --> BackgroundFetch["后台获取"]
UpdateCache --> ReturnData["返回数据"]
BackgroundFetch --> ReturnStale["返回过期数据"]
```

#### 缓存配置优化

```python
# 优化缓存配置
CACHE_CONFIG = {
    'us_stock_data': {
        'ttl_hours': 2,  # 美股数据缓存2小时
        'max_files': 2000,
        'description': '美股历史数据'
    },
    'china_stock_data': {
        'ttl_hours': 1,  # A股数据缓存1小时
        'max_files': 2000,
        'description': 'A股历史数据'
    }
}
```

## 监控与日志分析

### 日志配置

系统采用结构化日志记录，支持多种日志级别和格式。

#### 日志级别配置

| 级别 | 用途 | 示例场景 |
|------|------|----------|
| DEBUG | 详细调试信息 | API调用参数、内部状态 |
| INFO | 一般信息记录 | 数据获取成功、缓存命中 |
| WARNING | 警告信息 | 数据源降级、缓存失效 |
| ERROR | 错误信息 | API调用失败、网络错误 |
| CRITICAL | 严重错误 | 系统崩溃、数据丢失 |

#### 关键监控指标

```mermaid
graph TB
subgraph "性能指标"
RT[响应时间]
TP[吞吐量]
ER[错误率]
end
subgraph "资源指标"
CPU[CPU使用率]
MEM[内存使用率]
DISK[磁盘I/O]
end
subgraph "业务指标"
DR[数据获取成功率]
CR[缓存命中率]
AR[API调用成功率]
end
RT --> DR
TP --> CR
ER --> AR
CPU --> RT
MEM --> TP
DISK --> ER
```

### 告警配置

#### 关键告警阈值

| 指标 | 告警阈值 | 处理动作 |
|------|----------|----------|
| API错误率 | >5% | 自动降级数据源 |
| 缓存命中率 | <70% | 清理缓存并重新填充 |
| 响应时间 | >30秒 | 增加重试次数 |
| 磁盘空间 | <10% | 清理过期缓存 |
| 内存使用率 | >90% | 触发垃圾回收 |

### 日志分析工具

#### 关键日志模式

```python
# 错误日志分析
error_patterns = [
    r'\[ERROR\].*API.*timeout',
    r'\[WARNING\].*降级.*数据源',
    r'\[ERROR\].*缓存.*失败',
    r'\[CRITICAL\].*系统.*崩溃'
]

# 性能日志分析
perf_patterns = [
    r'\[INFO\].*耗时: (\d+\.\d+)s',
    r'\[INFO\].*数据条数: (\d+)',
    r'\[INFO\].*缓存命中.*(\d+)%'
]
```

## 故障排除工作流程

### 标准故障排除流程

```mermaid
flowchart TD
Incident[故障报告] --> Categorize{"故障分类"}
Categorize --> |数据获取| DataFlow["数据流故障排除"]
Categorize --> |缓存系统| CacheFlow["缓存故障排除"]
Categorize --> |配置问题| ConfigFlow["配置故障排除"]
DataFlow --> DiagnoseAPI["诊断API连接"]
DiagnoseAPI --> CheckAuth["检查认证配置"]
CheckAuth --> TestFallback["测试降级机制"]
CacheFlow --> CheckDisk["检查磁盘空间"]
CheckDisk --> ClearCache["清理缓存"]
ClearCache --> VerifyPerf["验证性能"]
ConfigFlow --> ValidateEnv["验证环境变量"]
ValidateEnv --> CheckFiles["检查配置文件"]
CheckFiles --> RestartService["重启服务"]
TestFallback --> Resolution["故障解决"]
VerifyPerf --> Resolution
RestartService --> Resolution
Resolution --> Document["记录解决方案"]
Document --> Monitor["持续监控"]
```

### 故障排除检查清单

#### 数据获取故障检查清单

- [ ] 检查网络连接状态
- [ ] 验证API密钥配置
- [ ] 确认数据源可用性
- [ ] 检查超时配置
- [ ] 验证降级机制
- [ ] 检查缓存状态
- [ ] 分析错误日志
- [ ] 测试备用数据源

#### 缓存系统故障检查清单

- [ ] 检查磁盘空间
- [ ] 验证目录权限
- [ ] 检查缓存配置
- [ ] 清理损坏文件
- [ ] 验证缓存算法
- [ ] 监控缓存性能
- [ ] 分析缓存日志
- [ ] 重建缓存索引

#### 配置问题检查清单

- [ ] 检查环境变量
- [ ] 验证配置文件
- [ ] 确认依赖库版本
- [ ] 检查端口占用
- [ ] 验证数据库连接
- [ ] 检查文件路径
- [ ] 重启相关服务
- [ ] 验证配置生效

### 自动化故障检测

#### 健康检查脚本

```python
# 健康检查示例
def health_check():
    checks = {
        'network': check_network(),
        'api_keys': check_api_keys(),
        'data_sources': check_data_sources(),
        'cache': check_cache(),
        'database': check_database()
    }
    
    overall_status = all(checks.values())
    return {
        'overall_status': overall_status,
        'details': checks
    }
```

#### 定期维护任务

```python
# 定期维护脚本
def scheduled_maintenance():
    tasks = [
        ('清理过期缓存', clear_expired_cache),
        ('备份配置文件', backup_config),
        ('检查磁盘空间', check_disk_space),
        ('验证API连接', test_api_connections),
        ('更新统计数据', update_statistics)
    ]
    
    for task_name, task_func in tasks:
        try:
            task_func()
            logger.info(f"✅ {task_name} 完成")
        except Exception as e:
            logger.error(f"❌ {task_name} 失败: {e}")
```

通过遵循本指南的故障排除流程和最佳实践，可以有效地诊断和解决TradingAgents-CN系统中的数据流与数据获取问题，确保系统的稳定性和可靠性。